import streamlit as st
from camel.messages import BaseMessage as bm
from camel.agents import ChatAgent
from camel.models import ModelFactory
from camel.types import ModelPlatformType
import os
from PIL import Image
from dotenv import load_dotenv
from camel.embeddings import SentenceTransformerEncoder
from camel.storages import QdrantStorage
from camel.retrievers import VectorRetriever
import tempfile
import shutil

load_dotenv()

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ™ºèƒ½æ—…æ¸¸åŠ©æ‰‹",
    page_icon="ğŸ–ï¸",
    layout="wide"
)

# ç¡®ä¿æœ¬åœ°æ•°æ®ç›®å½•å­˜åœ¨
if not os.path.exists('local_data'):
    os.makedirs('local_data')

# åˆå§‹åŒ–çŸ¥è¯†åº“ç»„ä»¶
@st.cache_resource
def initialize_knowledge_base():
    """åˆå§‹åŒ–çŸ¥è¯†åº“ç›¸å…³ç»„ä»¶"""
    try:
        # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
        embedding_model = SentenceTransformerEncoder(model_name='intfloat/e5-large-v2')
        
        # åˆå§‹åŒ–å‘é‡å­˜å‚¨
        vector_storage = QdrantStorage(
            vector_dim=embedding_model.get_output_dim(),
            collection="travel_collection",
            path="storage_travel_kb",
            collection_name="æ—…æ¸¸çŸ¥è¯†åº“"
        )
        
        # åˆå§‹åŒ–å‘é‡æ£€ç´¢å™¨
        vector_retriever = VectorRetriever(
            embedding_model=embedding_model,
            storage=vector_storage
        )
        
        return vector_retriever, embedding_model, vector_storage
    except Exception as e:
        st.error(f"çŸ¥è¯†åº“åˆå§‹åŒ–å¤±è´¥ï¼š{str(e)}")
        return None, None, None

# åˆå§‹åŒ–æ¨¡å‹å’ŒAgentï¼ˆä½¿ç”¨ç¼“å­˜é¿å…é‡å¤åˆ›å»ºï¼‰
@st.cache_resource
def initialize_agents():
    # API é…ç½®æ£€æŸ¥
    deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')
    qwen_api_key = os.getenv('QWEN_API_KEY')
    
    if not deepseek_api_key or not qwen_api_key:
        st.error("âŒ è¯·è®¾ç½®ç¯å¢ƒå˜é‡ DEEPSEEK_API_KEY å’Œ QWEN_API_KEY")
        st.stop()
    
    api_base = "https://api.siliconflow.cn/v1"
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ["OPENAI_API_KEY"] = deepseek_api_key
    os.environ["OPENAI_API_BASE"] = api_base
    
    # åˆ›å»ºæ–‡æœ¬å›ç­”è€…æ¨¡å‹ï¼ˆDeepSeek-V3ï¼‰
    answerer_model = ModelFactory.create(
        model_platform=ModelPlatformType.OPENAI_COMPATIBLE_MODEL,
        model_type="deepseek-ai/DeepSeek-V3",
        url=api_base,
        api_key=deepseek_api_key,
        model_config_dict={"max_tokens": 4096}
    )
    
    # åˆ›å»ºå›¾åƒç†è§£æ¨¡å‹ï¼ˆQwen2.5-VL-72B-Instructï¼‰
    vision_model = ModelFactory.create(
        model_platform=ModelPlatformType.OPENAI_COMPATIBLE_MODEL,
        model_type="Qwen/Qwen2.5-VL-72B-Instruct",
        url='https://api-inference.modelscope.cn/v1/',
        api_key=qwen_api_key,
        model_config_dict={"max_tokens": 4096},
    )
    
    # åˆ›å»ºè¯„ä¼°è€…æ¨¡å‹ï¼ˆDeepSeek-R1ï¼‰
    evaluator_model = ModelFactory.create(
        model_platform=ModelPlatformType.OPENAI_COMPATIBLE_MODEL,
        model_type="deepseek-ai/DeepSeek-V3",
        url=api_base,
        api_key=deepseek_api_key,
        model_config_dict={"max_tokens": 1024}
    )
    
    # æ–‡æœ¬å›ç­”è€… Agent
    answerer_agent = ChatAgent(
        system_message=bm.make_assistant_message(
            role_name="æ™ºèƒ½æ—…æ¸¸åŠ©æ‰‹",
            content="""
            ä½ æ˜¯ä¸€ä¸ª AI æ—…æ¸¸åŠ©æ‰‹ï¼Œè¯·ç”¨ä¸­æ–‡è¯¦ç»†å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚ä½ å¯¹æ—…æ¸¸è¡Œä¸šæœ‰æ·±å…¥çš„äº†è§£ï¼Œèƒ½å¤Ÿæ ¹æ®ç”¨æˆ·çš„éœ€æ±‚æä¾›è¯¦ç»†çš„æ—…æ¸¸æ–¹æ¡ˆã€‚
            å½“ç”¨æˆ·æä¾›å›¾ç‰‡æ—¶ï¼Œä½ ä¼šæ”¶åˆ°å›¾ç‰‡çš„æè¿°ä¿¡æ¯ï¼Œè¯·ç»“åˆå›¾ç‰‡å†…å®¹å’Œç”¨æˆ·é—®é¢˜æä¾›ç›¸å…³çš„æ—…æ¸¸å»ºè®®ã€‚
            å½“æä¾›äº†çŸ¥è¯†åº“ä¿¡æ¯æ—¶ï¼Œè¯·ä¼˜å…ˆå‚è€ƒçŸ¥è¯†åº“å†…å®¹æ¥å›ç­”é—®é¢˜ï¼Œå¹¶ç»“åˆä½ çš„æ—…æ¸¸çŸ¥è¯†æä¾›å…¨é¢çš„å»ºè®®ã€‚
            ä½ åªå¯¹æ—…æ¸¸æ–¹é¢çš„é—®é¢˜æœ‰å›åº”ï¼Œå¦‚æœç”¨æˆ·çš„é—®é¢˜ä¸æ—…æ¸¸æ— å…³ï¼Œè¯·ç¤¼è²Œåœ°å‘Šè¯‰ç”¨æˆ·ä½ åªå¯¹æ—…æ¸¸æ–¹é¢çš„é—®é¢˜æœ‰å›åº”ã€‚
            """
        ),
        model=answerer_model,
        message_window_size=10
    )
    
    # å›¾åƒç†è§£ Agent
    vision_agent = ChatAgent(
        system_message=bm.make_assistant_message(
            role_name="å›¾åƒåˆ†æå¸ˆ",
            content="ä½ æ˜¯ä¸€ä¸ªå›¾åƒåˆ†æä¸“å®¶ï¼Œè¯·ä»”ç»†è§‚å¯Ÿå›¾ç‰‡å¹¶ç”¨ä¸­æ–‡è¯¦ç»†æè¿°å›¾ç‰‡çš„å†…å®¹ï¼Œç‰¹åˆ«å…³æ³¨ä¸æ—…æ¸¸ç›¸å…³çš„å…ƒç´ ï¼Œå¦‚æ™¯ç‚¹ã€å»ºç­‘ã€è‡ªç„¶é£å…‰ã€æ–‡åŒ–ç‰¹è‰²ç­‰ã€‚"
        ),
        model=vision_model,
        output_language='ä¸­æ–‡'
    )
    
    # è¯„ä¼°è€… Agent
    evaluator_agent = ChatAgent(
        system_message=bm.make_assistant_message(
            role_name="è¯„ä¼°ä¸“å®¶",
            content="ä½ æ˜¯ä¸€ä¸ª AI è¯„ä¼°å‘˜ï¼Œè¯„ä»·aiå¯¹ç”¨æˆ·é—®é¢˜çš„å›ç­”è´¨é‡ä»¥åŠç¬¦åˆç”¨æˆ·éœ€æ±‚ç¨‹åº¦ï¼Œè¯·å¯¹å›ç­”è¿›è¡Œæ‰“åˆ†ï¼ˆ1~10ï¼‰ï¼Œå¹¶è¯´æ˜åŸå› ã€‚æ³¨æ„æ‰“åˆ†æ—¶è¾“å‡ºå•ä¸ªæ•°å­—ç„¶åç©ºæ ¼åŠ ä¸Šç†ç”±ï¼Œä¸éœ€è¦ç±»ä¼¼äº'xåˆ†'è¿™æ ·çš„åç¼€ã€‚"
        ),
        model=evaluator_model,
        message_window_size=10
    )
    
    # çŸ¥è¯†åº“åŠ©æ‰‹ Agent
    kb_agent = ChatAgent(
        system_message=bm.make_assistant_message(
            role_name="çŸ¥è¯†åº“åŠ©æ‰‹",
            content="""
            ä½ æ˜¯ä¸€ä¸ªå¸®åŠ©å›ç­”é—®é¢˜çš„åŠ©æ‰‹ï¼Œ
            æˆ‘ä¼šç»™ä½ åŸå§‹æŸ¥è¯¢å’Œæ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ï¼Œ
            æ ¹æ®æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡å›ç­”åŸå§‹æŸ¥è¯¢ï¼Œ
            å¦‚æœä½ æ— æ³•å›ç­”é—®é¢˜å°±è¯´æˆ‘ä¸çŸ¥é“ã€‚
            è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œå¹¶ä¸“æ³¨äºæ—…æ¸¸ç›¸å…³çš„ä¿¡æ¯ã€‚
            """
        ),
        model=answerer_model,
        output_language='ä¸­æ–‡'
    )
    
    return answerer_agent, vision_agent, evaluator_agent, kb_agent

def process_uploaded_file(uploaded_file, vector_retriever):
    """å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶å¹¶æ·»åŠ åˆ°çŸ¥è¯†åº“"""
    try:
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            tmp_file_path = tmp_file.name
        
        # å°†æ–‡ä»¶å¤åˆ¶åˆ°local_dataç›®å½•
        local_file_path = os.path.join('local_data', uploaded_file.name)
        shutil.copy2(tmp_file_path, local_file_path)
        
        # å¤„ç†æ–‡ä»¶å¹¶æ·»åŠ åˆ°å‘é‡æ•°æ®åº“
        vector_retriever.process(content=local_file_path)
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        os.unlink(tmp_file_path)
        
        return True, local_file_path
    except Exception as e:
        return False, str(e)

def query_knowledge_base(query, vector_retriever, top_k=3):
    """æŸ¥è¯¢çŸ¥è¯†åº“"""
    try:
        retrieved_info = vector_retriever.query(query=query, top_k=top_k)
        return retrieved_info
    except Exception as e:
        st.error(f"çŸ¥è¯†åº“æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}")
        return []

def analyze_image(image, vision_agent):
    """åˆ†æä¸Šä¼ çš„å›¾ç‰‡"""
    try:
        vision_msg = bm.make_user_message(
            role_name="User", 
            content="è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ï¼Œç‰¹åˆ«å…³æ³¨ä¸æ—…æ¸¸ç›¸å…³çš„å…ƒç´ ", 
            image_list=[image]
        )
        
        response = vision_agent.step(vision_msg)
        
        # æ£€æŸ¥å“åº”æ˜¯å¦æœ‰æ•ˆ
        if not response or not hasattr(response, 'msgs') or not response.msgs:
            st.error("å›¾ç‰‡åˆ†æå¤±è´¥ï¼šAPIè¿”å›ç©ºå“åº”")
            return None
            
        image_description = response.msgs[0].content
        return image_description
    except Exception as e:
        st.error(f"å›¾ç‰‡åˆ†æå¤±è´¥ï¼š{str(e)}")
        return None

def process_question_with_knowledge(user_question, image_description, vector_retriever, answerer_agent, kb_agent, evaluator_agent, use_kb=True):
    """å¤„ç†åŒ…å«çŸ¥è¯†åº“æ£€ç´¢çš„ç”¨æˆ·é—®é¢˜"""
    knowledge_info = ""
    
    # å¦‚æœå¯ç”¨çŸ¥è¯†åº“ï¼Œå…ˆæ£€ç´¢ç›¸å…³ä¿¡æ¯
    if use_kb and vector_retriever:
        try:
            retrieved_info = query_knowledge_base(user_question, vector_retriever)
            if retrieved_info:
                knowledge_texts = [info['text'] for info in retrieved_info]
                knowledge_info = "\n\n".join(knowledge_texts)
        except Exception as e:
            st.warning(f"çŸ¥è¯†åº“æ£€ç´¢å¤±è´¥ï¼Œå°†ä½¿ç”¨åŸºç¡€æ¨¡å¼ï¼š{str(e)}")
    
    # æ„å»ºå®Œæ•´é—®é¢˜
    full_question = f"ç”¨æˆ·é—®é¢˜ï¼š{user_question}\n\n"
    
    if image_description:
        full_question += f"å›¾ç‰‡æè¿°ï¼š{image_description}\n\n"
    
    if knowledge_info:
        full_question += f"çŸ¥è¯†åº“ç›¸å…³ä¿¡æ¯ï¼š\n{knowledge_info}\n\n"
    
    full_question += "è¯·ç»“åˆä»¥ä¸Šä¿¡æ¯å›ç­”ç”¨æˆ·çš„æ—…æ¸¸ç›¸å…³é—®é¢˜ã€‚"
    
    usr_msg = bm.make_user_message(
        role_name='ç”¨æˆ·',
        content=full_question
    )
    
    max_retries = 3
    attempts = 0
    final_answer = None
    is_satisfied = False
    process_log = []
    
    while attempts < max_retries and not is_satisfied:
        attempts += 1
        process_log.append(f"ğŸ”„ å°è¯•ç¬¬ {attempts} æ¬¡ç”Ÿæˆå›ç­”...")
        
        try:
            # Step 1: å›ç­”è€…ç”Ÿæˆç­”æ¡ˆ
            answer_response = answerer_agent.step(usr_msg)
            
            # æ£€æŸ¥å›ç­”å“åº”æ˜¯å¦æœ‰æ•ˆ
            if not answer_response or not hasattr(answer_response, 'msgs') or not answer_response.msgs:
                process_log.append("âŒ å›ç­”ç”Ÿæˆå¤±è´¥ï¼šAPIè¿”å›ç©ºå“åº”")
                final_answer = "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ç”Ÿæˆå›ç­”ï¼Œè¯·ç¨åé‡è¯•ã€‚"
                break
                
            answer_content = answer_response.msgs[0].content
            process_log.append(f"ã€å›ç­”è€…å›å¤ã€‘\n{answer_content}")
            
            # Step 2: æ„é€ è¯„ä¼°è¯·æ±‚
            evaluation_prompt = f"""
è¯·è¯„ä¼°ä»¥ä¸‹é—®ç­”è¿‡ç¨‹çš„è´¨é‡ï¼š

ã€ç”¨æˆ·æé—®ã€‘
{user_question}

ã€å›¾ç‰‡ä¿¡æ¯ã€‘
{image_description if image_description else "æ— å›¾ç‰‡"}

ã€çŸ¥è¯†åº“ä¿¡æ¯ã€‘
{knowledge_info if knowledge_info else "æœªä½¿ç”¨çŸ¥è¯†åº“"}

ã€å›ç­”è€…å›å¤ã€‘
{answer_content}

ã€è¯„åˆ†æ ‡å‡†ã€‘
è¯·ä»å‡†ç¡®æ€§ã€å®Œæ•´æ€§ã€æ¸…æ™°åº¦ç­‰æ–¹é¢è¿›è¡Œæ‰“åˆ†ï¼ˆ1~10ï¼‰ï¼Œå¹¶ç®€è¦è¯´æ˜ç†ç”±ã€‚

è¯·åªè¿”å›ä¸€ä¸ªæ•°å­— + ç®€è¦ç†ç”±ã€‚
"""
            
            evaluation_msg = bm.make_user_message(
                role_name='è¯„ä¼°å™¨',
                content=evaluation_prompt
            )
            
            # Step 3: è¯„ä¼°è€…åˆ†æå›ç­”è´¨é‡
            try:
                evaluation_response = evaluator_agent.step(evaluation_msg)
                
                # æ£€æŸ¥è¯„ä¼°å“åº”æ˜¯å¦æœ‰æ•ˆ
                if not evaluation_response or not hasattr(evaluation_response, 'msgs') or not evaluation_response.msgs:
                    process_log.append("âš ï¸ è¯„ä¼°å¤±è´¥ï¼šAPIè¿”å›ç©ºå“åº”ï¼Œé»˜è®¤é€šè¿‡")
                    final_answer = answer_content
                    is_satisfied = True
                    break
                    
                evaluation_content = evaluation_response.msgs[0].content.strip()
                process_log.append(f"ã€è¯„ä¼°ç»“æœã€‘\n{evaluation_content}")
                
                # Step 4: åˆ¤æ–­æ˜¯å¦æ»¡æ„
                try:
                    score = int(evaluation_content.split()[0])
                    if score >= 6:
                        is_satisfied = True
                        final_answer = answer_content
                        process_log.append(f"âœ… è¯„åˆ†è¾¾æ ‡ï¼ˆ{score}åˆ†ï¼‰ï¼Œç”Ÿæˆå®Œæˆï¼")
                    else:
                        improve_msg = bm.make_user_message(
                            role_name='è¯„ä¼°åé¦ˆ',
                            content=f"ä½ çš„å›ç­”å¾—åˆ† {score} åˆ†ï¼Œä¸å¤Ÿç†æƒ³ã€‚è¯·æ ¹æ®ä»¥ä¸‹å»ºè®®æ”¹è¿›ï¼š{evaluation_content}"
                        )
                        answerer_agent.update_messages(improve_msg)
                        process_log.append(f"âŒ è¯„åˆ†ä¸è¾¾æ ‡ï¼ˆ{score}åˆ†ï¼‰ï¼Œå‡†å¤‡é‡æ–°ç”Ÿæˆ...")
                except (ValueError, IndexError) as e:
                    process_log.append(f"âš ï¸ æ— æ³•è§£æè¯„åˆ†ï¼Œé»˜è®¤é€šè¿‡ï¼š{str(e)}")
                    final_answer = answer_content
                    is_satisfied = True
                    
            except Exception as e:
                process_log.append(f"âš ï¸ è¯„ä¼°è¿‡ç¨‹å‡ºé”™ï¼Œé»˜è®¤é€šè¿‡ï¼š{str(e)}")
                final_answer = answer_content
                is_satisfied = True
                
        except Exception as e:
            process_log.append(f"âŒ ç¬¬{attempts}æ¬¡å°è¯•å¤±è´¥ï¼š{str(e)}")
            if attempts == max_retries:
                final_answer = "æŠ±æ­‰ï¼Œç³»ç»Ÿé‡åˆ°é—®é¢˜ï¼Œè¯·ç¨åé‡è¯•ã€‚"
    
    # å¦‚æœæ‰€æœ‰å°è¯•éƒ½å¤±è´¥äº†ï¼Œæä¾›é»˜è®¤å›ç­”
    if final_answer is None:
        final_answer = "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ä¸ºæ‚¨æä¾›æ»¡æ„çš„å›ç­”ï¼Œè¯·ç¨åé‡è¯•æˆ–é‡æ–°æè¿°æ‚¨çš„é—®é¢˜ã€‚"
        process_log.append("âŒ æ‰€æœ‰å°è¯•éƒ½å¤±è´¥ï¼Œè¿”å›é»˜è®¤å›ç­”")
    
    return final_answer, process_log, knowledge_info

# ä¸»ç•Œé¢
def main():
    st.title("ğŸ–ï¸ æ™ºèƒ½æ—…æ¸¸åŠ©æ‰‹")
    st.markdown("æ”¯æŒæ–‡å­—é—®ç­”ã€å›¾ç‰‡åˆ†æå’ŒçŸ¥è¯†åº“æ£€ç´¢çš„æ—…æ¸¸å’¨è¯¢æœåŠ¡")
    st.markdown("---")
    
    # åˆå§‹åŒ–agentså’ŒçŸ¥è¯†åº“
    try:
        answerer_agent, vision_agent, evaluator_agent, kb_agent = initialize_agents()
        vector_retriever, embedding_model, vector_storage = initialize_knowledge_base()
    except Exception as e:
        st.error(f"åˆå§‹åŒ–å¤±è´¥ï¼š{str(e)}")
        st.stop()
    
    # ä¾§è¾¹æ è®¾ç½®
    with st.sidebar:
        st.header("âš™ï¸ åŠŸèƒ½è®¾ç½®")
        st.info("è¿™æ˜¯ä¸€ä¸ªä¸“é—¨å›ç­”æ—…æ¸¸ç›¸å…³é—®é¢˜çš„AIåŠ©æ‰‹ï¼Œæ”¯æŒå›¾ç‰‡ä¸Šä¼ ã€çŸ¥è¯†åº“æ£€ç´¢å’Œåˆ†æ")
        
        # åŠŸèƒ½é€‰æ‹©
        st.subheader("ğŸ“‹ åŠŸèƒ½æ¨¡å¼")
        mode = st.radio(
            "é€‰æ‹©å’¨è¯¢æ¨¡å¼ï¼š",
            ["çº¯æ–‡å­—å’¨è¯¢", "å›¾ç‰‡+æ–‡å­—å’¨è¯¢", "çŸ¥è¯†åº“+æ–‡å­—å’¨è¯¢", "å…¨åŠŸèƒ½æ¨¡å¼"],
            index=0
        )
        st.markdown("---")
        st.subheader("ğŸ”— ç½‘é¡µç”Ÿæˆ")
        st.markdown(
            "ğŸŒ [ä¸€é”®ç”Ÿæˆæ”»ç•¥](http://localhost:5000)",
            help="ç‚¹å‡»è·³è½¬åˆ° localhost:5000"
        )
        # çŸ¥è¯†åº“è®¾ç½®
        if mode in ["çŸ¥è¯†åº“+æ–‡å­—å’¨è¯¢", "å…¨åŠŸèƒ½æ¨¡å¼"]:
            st.subheader("ğŸ“š çŸ¥è¯†åº“ç®¡ç†")
            
            # æ–‡ä»¶ä¸Šä¼ 
            uploaded_kb_file = st.file_uploader(
                "ä¸Šä¼ PDFæ–‡ä»¶åˆ°çŸ¥è¯†åº“",
                type=['pdf'],
                help="æ”¯æŒPDFæ ¼å¼çš„æ—…æ¸¸ç›¸å…³æ–‡æ¡£"
            )
            
            if uploaded_kb_file is not None:
                if st.button("ğŸ“¥ æ·»åŠ åˆ°çŸ¥è¯†åº“"):
                    with st.spinner("æ­£åœ¨å¤„ç†æ–‡ä»¶å¹¶æ·»åŠ åˆ°çŸ¥è¯†åº“..."):
                        success, result = process_uploaded_file(uploaded_kb_file, vector_retriever)
                        if success:
                            st.success(f"âœ… æ–‡ä»¶å·²æˆåŠŸæ·»åŠ åˆ°çŸ¥è¯†åº“ï¼š{result}")
                            st.session_state.kb_files_count = st.session_state.get('kb_files_count', 0) + 1
                        else:
                            st.error(f"âŒ æ–‡ä»¶æ·»åŠ å¤±è´¥ï¼š{result}")
            
            # çŸ¥è¯†åº“ç»Ÿè®¡
            kb_count = st.session_state.get('kb_files_count', 0)
            st.metric("çŸ¥è¯†åº“æ–‡ä»¶æ•°", kb_count)
        
        # ç¤ºä¾‹é—®é¢˜
        st.subheader("ğŸ’¡ ç¤ºä¾‹é—®é¢˜")
        if mode == "çº¯æ–‡å­—å’¨è¯¢":
            example_questions = [
                "æ¨èä¸€ä¸ªé€‚åˆå®¶åº­å‡ºæ¸¸çš„æµ·è¾¹åŸå¸‚",
                "å»æ—¥æœ¬æ—…æ¸¸éœ€è¦å‡†å¤‡ä»€ä¹ˆï¼Ÿ",
                "é¢„ç®—5000å…ƒçš„å›½å†…ä¸‰æ—¥æ¸¸æ¨è",
                "ä»€ä¹ˆæ—¶å€™å»æ–°ç–†æ—…æ¸¸æœ€åˆé€‚ï¼Ÿ"
            ]
        elif mode == "å›¾ç‰‡+æ–‡å­—å’¨è¯¢":
            example_questions = [
                "è¿™ä¸ªåœ°æ–¹é€‚åˆä»€ä¹ˆæ—¶å€™å»æ—…æ¸¸ï¼Ÿ",
                "åˆ†æä¸€ä¸‹è¿™ä¸ªæ™¯ç‚¹çš„ç‰¹è‰²",
                "æ ¹æ®å›¾ç‰‡æ¨èç±»ä¼¼çš„æ—…æ¸¸ç›®çš„åœ°",
                "è¿™é‡Œæœ‰ä»€ä¹ˆå€¼å¾—ä½“éªŒçš„æ´»åŠ¨ï¼Ÿ"
            ]
        elif mode == "çŸ¥è¯†åº“+æ–‡å­—å’¨è¯¢":
            example_questions = [
                "æ ¹æ®çŸ¥è¯†åº“ä¿¡æ¯æ¨èæ—…æ¸¸è·¯çº¿",
                "çŸ¥è¯†åº“ä¸­æœ‰å“ªäº›æ™¯ç‚¹ä»‹ç»ï¼Ÿ",
                "æŸ¥è¯¢ç‰¹å®šåœ°åŒºçš„æ—…æ¸¸æ”»ç•¥",
                "æ ¹æ®æ–‡æ¡£æ¨èæœ€ä½³æ—…æ¸¸æ—¶é—´"
            ]
        else:  # å…¨åŠŸèƒ½æ¨¡å¼
            example_questions = [
                "ç»“åˆå›¾ç‰‡å’ŒçŸ¥è¯†åº“æ¨èæ—…æ¸¸æ–¹æ¡ˆ",
                "è¿™ä¸ªæ™¯ç‚¹åœ¨çŸ¥è¯†åº“ä¸­æœ‰ç›¸å…³ä»‹ç»å—ï¼Ÿ",
                "æ ¹æ®å›¾ç‰‡å’Œæ–‡æ¡£åˆ†ææ—…æ¸¸ä»·å€¼",
                "ç»¼åˆä¿¡æ¯åˆ¶å®šè¯¦ç»†æ—…æ¸¸è®¡åˆ’"
            ]
        
        for i, question in enumerate(example_questions):
            if st.button(question, key=f"example_{i}"):
                st.session_state.user_input = question
    
    # ä¸»è¦å†…å®¹åŒºåŸŸ
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸ’¬ å’¨è¯¢åŒºåŸŸ")
        
        # å›¾ç‰‡ä¸Šä¼ åŒºåŸŸ
        uploaded_image = None
        if mode in ["å›¾ç‰‡+æ–‡å­—å’¨è¯¢", "å…¨åŠŸèƒ½æ¨¡å¼"]:
            st.subheader("ğŸ“¸ ä¸Šä¼ å›¾ç‰‡")
            uploaded_file = st.file_uploader(
                "é€‰æ‹©ä¸€å¼ æ—…æ¸¸ç›¸å…³çš„å›¾ç‰‡",
                type=['png', 'jpg', 'jpeg'],
                help="æ”¯æŒPNGã€JPGã€JPEGæ ¼å¼"
            )
            
            if uploaded_file is not None:
                uploaded_image = Image.open(uploaded_file)
                st.image(uploaded_image, caption="ä¸Šä¼ çš„å›¾ç‰‡", use_container_width=True)
        
        # ç”¨æˆ·è¾“å…¥
        user_input = st.text_area(
            "è¯·è¾“å…¥æ‚¨çš„æ—…æ¸¸ç›¸å…³é—®é¢˜ï¼š",
            height=100,
            placeholder=f"ä¾‹å¦‚ï¼š{example_questions[0]}",
            key="user_input"
        )
        
        # æäº¤æŒ‰é’®
        if st.button("ğŸš€ æäº¤å’¨è¯¢", type="primary"):
            if user_input.strip():
                image_description = None
                use_kb = mode in ["çŸ¥è¯†åº“+æ–‡å­—å’¨è¯¢", "å…¨åŠŸèƒ½æ¨¡å¼"]
                
                # å¦‚æœæœ‰å›¾ç‰‡ï¼Œå…ˆåˆ†æå›¾ç‰‡
                if uploaded_image is not None:
                    with st.spinner("æ­£åœ¨åˆ†æå›¾ç‰‡..."):
                        image_description = analyze_image(uploaded_image, vision_agent)
                        if image_description:
                            st.success("âœ… å›¾ç‰‡åˆ†æå®Œæˆ")
                        else:
                            st.error("âŒ å›¾ç‰‡åˆ†æå¤±è´¥ï¼Œå°†ç»§ç»­å¤„ç†æ–‡å­—é—®é¢˜")
                
                # å¤„ç†é—®é¢˜
                with st.spinner("æ­£åœ¨æ€è€ƒç­”æ¡ˆï¼Œè¯·ç¨å€™..."):
                    final_answer, process_log, knowledge_info = process_question_with_knowledge(
                        user_input, image_description, vector_retriever if use_kb else None, 
                        answerer_agent, kb_agent, evaluator_agent, use_kb
                    )
                
                # å­˜å‚¨ç»“æœåˆ°session state
                st.session_state.final_answer = final_answer
                st.session_state.process_log = process_log
                st.session_state.user_question = user_input
                st.session_state.image_description = image_description
                st.session_state.uploaded_image = uploaded_image
                st.session_state.knowledge_info = knowledge_info
            else:
                st.warning("è¯·è¾“å…¥é—®é¢˜åå†æäº¤ï¼")
    
    with col2:
        st.subheader("ğŸ“Š ä½¿ç”¨ç»Ÿè®¡")
        
        # é—®é¢˜ç»Ÿè®¡
        if 'question_count' not in st.session_state:
            st.session_state.question_count = 0
        st.metric("å·²å›ç­”é—®é¢˜", st.session_state.question_count)
        
        # å›¾ç‰‡ç»Ÿè®¡
        if 'image_count' not in st.session_state:
            st.session_state.image_count = 0
        st.metric("å·²åˆ†æå›¾ç‰‡", st.session_state.image_count)
        
        # çŸ¥è¯†åº“ç»Ÿè®¡
        kb_count = st.session_state.get('kb_files_count', 0)
        st.metric("çŸ¥è¯†åº“æ–‡ä»¶", kb_count)
    
    # æ˜¾ç¤ºç»“æœ
    if hasattr(st.session_state, 'final_answer') and st.session_state.final_answer:
        st.markdown("---")
        st.subheader("âœ… å’¨è¯¢ç»“æœ")
        
        # æ˜¾ç¤ºä¸Šä¼ çš„å›¾ç‰‡ï¼ˆå¦‚æœæœ‰ï¼‰
        if hasattr(st.session_state, 'uploaded_image') and st.session_state.uploaded_image:
            col_img, col_desc = st.columns([1, 1])
            with col_img:
                st.image(st.session_state.uploaded_image, caption="æ‚¨ä¸Šä¼ çš„å›¾ç‰‡", use_container_width=True)
            
            with col_desc:
                if hasattr(st.session_state, 'image_description') and st.session_state.image_description:
                    with st.expander("ğŸ” å›¾ç‰‡åˆ†æç»“æœ", expanded=True):
                        st.write(st.session_state.image_description)
        
        # æ˜¾ç¤ºçŸ¥è¯†åº“ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        if hasattr(st.session_state, 'knowledge_info') and st.session_state.knowledge_info:
            with st.expander("ğŸ“š çŸ¥è¯†åº“æ£€ç´¢ç»“æœ", expanded=False):
                st.write(st.session_state.knowledge_info)
        
        # ç”¨æˆ·é—®é¢˜
        with st.expander("ğŸ“ æ‚¨çš„é—®é¢˜", expanded=True):
            st.write(st.session_state.user_question)
        
        # æœ€ç»ˆç­”æ¡ˆ
        st.success("**AIæ—…æ¸¸åŠ©æ‰‹å›ç­”ï¼š**")
        st.write(st.session_state.final_answer)
        
        # å¤„ç†è¿‡ç¨‹ï¼ˆå¯æŠ˜å ï¼‰
        with st.expander("ğŸ” æŸ¥çœ‹å¤„ç†è¿‡ç¨‹"):
            for log_entry in st.session_state.process_log:
                st.text(log_entry)
        
        # åé¦ˆåŒºåŸŸ
        st.subheader("ğŸ“ åé¦ˆ")
        feedback_col1, feedback_col2 = st.columns(2)
        
        with feedback_col1:
            if st.button("ğŸ‘ æ»¡æ„"):
                st.success("æ„Ÿè°¢æ‚¨çš„åé¦ˆï¼")
                st.session_state.question_count += 1
                if hasattr(st.session_state, 'uploaded_image') and st.session_state.uploaded_image:
                    st.session_state.image_count += 1
        
        with feedback_col2:
            if st.button("ğŸ‘ ä¸æ»¡æ„"):
                st.info("æˆ‘ä»¬ä¼šç»§ç»­æ”¹è¿›ï¼Œæ„Ÿè°¢æ‚¨çš„åé¦ˆï¼")

if __name__ == "__main__":
    main()
